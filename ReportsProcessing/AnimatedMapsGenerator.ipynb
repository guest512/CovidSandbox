{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import itertools\n",
    "import shutil\n",
    "import argparse\n",
    "\n",
    "from matplotlib import pyplot, cm, colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool, cpu_count\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Creates video animations from COVID daily reports\")\n",
    "parser.add_argument(\"--minimal\", \"--min\", action='store_true', default=False, help=\"Create only necessary animations\")\n",
    "\n",
    "args = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare environment and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_shape_df=gpd.read_file('maps/ne_10m_admin_0_sovereignty.shp')\n",
    "world_states_shape_df = gpd.read_file('maps/ne_10m_admin_1_states_provinces.shp')\n",
    "\n",
    "russia_shape_df = None if args[0].minimal else world_states_shape_df[world_states_shape_df.admin == 'Russia']\n",
    "\n",
    "world_report_df = utils.storage.get_countries_report()\n",
    "russia_report_df = None if args[0].minimal else utils.storage.get_regions_report('Russia')\n",
    "\n",
    "world_report_df.reset_index(inplace=True)\n",
    "if russia_report_df is not None:\n",
    "    russia_report_df.reset_index(inplace=True)\n",
    "\n",
    "if not os.path.exists('./assets'):\n",
    "    os.mkdir('./assets')\n",
    "    os.mkdir('./assets/video')\n",
    "elif not os.path.exists('./assets/video'):\n",
    "    os.mkdir('./assets/video')\n",
    "    \n",
    "if not os.path.exists('./temp'):\n",
    "    os.mkdir('./temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data - add more metrics if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add new columns to world report: 100%|██████████| 189/189 [00:27<00:00,  6.91it/s]\n",
      "Add new columns to russia report: 100%|██████████| 86/86 [00:08<00:00, 10.70it/s]\n"
     ]
    }
   ],
   "source": [
    "world_stats = utils.storage.get_countries_stats()\n",
    "\n",
    "def augment_report(df, country, region = None):\n",
    "    columns = ['Confirmed', 'Deaths', 'Confirmed_Change', 'Deaths_Change', 'Rt']\n",
    "\n",
    "    name = country\n",
    "    if region:\n",
    "        name = region\n",
    "        \n",
    "    if name == 'Main territory':\n",
    "        df.drop(df[df.Name == name].index ,inplace=True)\n",
    "        return\n",
    "        \n",
    "    for column in columns:\n",
    "        values =  df.loc[df.Name == name, ['Date', column]].sort_values(by='Date')[column]\n",
    "        \n",
    "        for sma in [3, 5, 7, 10, 14]:\n",
    "            df.loc[df.Name == name, column + '_SMA_' + str(sma)] = values.rolling(window=sma).mean()\n",
    "            \n",
    "        if column == 'Rt':\n",
    "            continue\n",
    "        \n",
    "        df.loc[df.Name == name, column + '_Norm'] = utils.data.normalize(values)\n",
    "\n",
    "        values_per_capita = utils.data.per_capita(values, country, region)\n",
    "        for per in [1, 1_000, 100_000]:\n",
    "            suffix = 'per_capita'\n",
    "            if per == 1000:\n",
    "                suffix = 'per_1k'\n",
    "            elif per == 100_000:\n",
    "                suffix = 'per_100k'\n",
    "            \n",
    "            df.loc[df.Name == name, column + '_' + suffix] = values_per_capita * per\n",
    "    \n",
    "    \n",
    "\n",
    "for country in tqdm(utils.storage.get_countries(), desc='Add new columns to world report'):\n",
    "    augment_report(world_report_df, country)\n",
    "    world_report_df.loc[world_report_df.Name == country, 'Continent'] = world_stats.loc[country, 'Continent']\n",
    "\n",
    "if not args[0].minimal:\n",
    "    for region in tqdm(utils.storage.get_country_regions('Russia'), desc='Add new columns to russia report'):\n",
    "        augment_report(russia_report_df, 'Russia', region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Active</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Confirmed_Change</th>\n",
       "      <th>Active_Change</th>\n",
       "      <th>Recovered_Change</th>\n",
       "      <th>Deaths_Change</th>\n",
       "      <th>...</th>\n",
       "      <th>Deaths_Change_SMA_14</th>\n",
       "      <th>Deaths_Change_Norm</th>\n",
       "      <th>Deaths_Change_per_capita</th>\n",
       "      <th>Deaths_Change_per_1k</th>\n",
       "      <th>Deaths_Change_per_100k</th>\n",
       "      <th>Rt_SMA_3</th>\n",
       "      <th>Rt_SMA_5</th>\n",
       "      <th>Rt_SMA_7</th>\n",
       "      <th>Rt_SMA_10</th>\n",
       "      <th>Rt_SMA_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27859</th>\n",
       "      <td>319</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>19252</td>\n",
       "      <td>1051</td>\n",
       "      <td>18079</td>\n",
       "      <td>122</td>\n",
       "      <td>188</td>\n",
       "      <td>70</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.316035</td>\n",
       "      <td>1.005755</td>\n",
       "      <td>1.006389</td>\n",
       "      <td>1.006282</td>\n",
       "      <td>1.007772</td>\n",
       "      <td>1.006039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27860</th>\n",
       "      <td>320</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>19444</td>\n",
       "      <td>1101</td>\n",
       "      <td>18218</td>\n",
       "      <td>125</td>\n",
       "      <td>192</td>\n",
       "      <td>50</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.237026</td>\n",
       "      <td>1.004424</td>\n",
       "      <td>1.006120</td>\n",
       "      <td>1.005323</td>\n",
       "      <td>1.006553</td>\n",
       "      <td>1.006613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27861</th>\n",
       "      <td>321</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>19637</td>\n",
       "      <td>1118</td>\n",
       "      <td>18389</td>\n",
       "      <td>130</td>\n",
       "      <td>193</td>\n",
       "      <td>17</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.785714</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.395043</td>\n",
       "      <td>1.005295</td>\n",
       "      <td>1.005302</td>\n",
       "      <td>1.005884</td>\n",
       "      <td>1.005859</td>\n",
       "      <td>1.007468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27862</th>\n",
       "      <td>322</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>19827</td>\n",
       "      <td>1126</td>\n",
       "      <td>18565</td>\n",
       "      <td>136</td>\n",
       "      <td>190</td>\n",
       "      <td>8</td>\n",
       "      <td>176</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>0.474052</td>\n",
       "      <td>1.005724</td>\n",
       "      <td>1.005825</td>\n",
       "      <td>1.006636</td>\n",
       "      <td>1.006115</td>\n",
       "      <td>1.007454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27863</th>\n",
       "      <td>323</td>\n",
       "      <td>2020-12-19</td>\n",
       "      <td>20017</td>\n",
       "      <td>1130</td>\n",
       "      <td>18746</td>\n",
       "      <td>141</td>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>181</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.395043</td>\n",
       "      <td>1.008362</td>\n",
       "      <td>1.006609</td>\n",
       "      <td>1.006239</td>\n",
       "      <td>1.006235</td>\n",
       "      <td>1.007438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27540 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index       Date  Confirmed  Active  Recovered  Deaths  \\\n",
       "324        0 2020-01-31          0       0          0       0   \n",
       "325        1 2020-02-01          0       0          0       0   \n",
       "326        2 2020-02-02          0       0          0       0   \n",
       "327        3 2020-02-03          0       0          0       0   \n",
       "328        4 2020-02-04          0       0          0       0   \n",
       "...      ...        ...        ...     ...        ...     ...   \n",
       "27859    319 2020-12-15      19252    1051      18079     122   \n",
       "27860    320 2020-12-16      19444    1101      18218     125   \n",
       "27861    321 2020-12-17      19637    1118      18389     130   \n",
       "27862    322 2020-12-18      19827    1126      18565     136   \n",
       "27863    323 2020-12-19      20017    1130      18746     141   \n",
       "\n",
       "       Confirmed_Change  Active_Change  Recovered_Change  Deaths_Change  ...  \\\n",
       "324                   0              0                 0              0  ...   \n",
       "325                   0              0                 0              0  ...   \n",
       "326                   0              0                 0              0  ...   \n",
       "327                   0              0                 0              0  ...   \n",
       "328                   0              0                 0              0  ...   \n",
       "...                 ...            ...               ...            ...  ...   \n",
       "27859               188             70               114              4  ...   \n",
       "27860               192             50               139              3  ...   \n",
       "27861               193             17               171              5  ...   \n",
       "27862               190              8               176              6  ...   \n",
       "27863               190              4               181              5  ...   \n",
       "\n",
       "       Deaths_Change_SMA_14  Deaths_Change_Norm Deaths_Change_per_capita  \\\n",
       "324                     NaN            0.000000                 0.000000   \n",
       "325                     NaN            0.000000                 0.000000   \n",
       "326                     NaN            0.000000                 0.000000   \n",
       "327                     NaN            0.000000                 0.000000   \n",
       "328                     NaN            0.000000                 0.000000   \n",
       "...                     ...                 ...                      ...   \n",
       "27859              2.642857            0.666667                 0.000003   \n",
       "27860              2.642857            0.500000                 0.000002   \n",
       "27861              2.785714            0.833333                 0.000004   \n",
       "27862              3.000000            1.000000                 0.000005   \n",
       "27863              3.071429            0.833333                 0.000004   \n",
       "\n",
       "       Deaths_Change_per_1k  Deaths_Change_per_100k  Rt_SMA_3  Rt_SMA_5  \\\n",
       "324                0.000000                0.000000       NaN       NaN   \n",
       "325                0.000000                0.000000       NaN       NaN   \n",
       "326                0.000000                0.000000  0.000000       NaN   \n",
       "327                0.000000                0.000000  0.000000       NaN   \n",
       "328                0.000000                0.000000  0.000000  0.000000   \n",
       "...                     ...                     ...       ...       ...   \n",
       "27859              0.003160                0.316035  1.005755  1.006389   \n",
       "27860              0.002370                0.237026  1.004424  1.006120   \n",
       "27861              0.003950                0.395043  1.005295  1.005302   \n",
       "27862              0.004741                0.474052  1.005724  1.005825   \n",
       "27863              0.003950                0.395043  1.008362  1.006609   \n",
       "\n",
       "       Rt_SMA_7  Rt_SMA_10  Rt_SMA_14  \n",
       "324         NaN        NaN        NaN  \n",
       "325         NaN        NaN        NaN  \n",
       "326         NaN        NaN        NaN  \n",
       "327         NaN        NaN        NaN  \n",
       "328         NaN        NaN        NaN  \n",
       "...         ...        ...        ...  \n",
       "27859  1.006282   1.007772   1.006039  \n",
       "27860  1.005323   1.006553   1.006613  \n",
       "27861  1.005884   1.005859   1.007468  \n",
       "27862  1.006636   1.006115   1.007454  \n",
       "27863  1.006239   1.006235   1.007438  \n",
       "\n",
       "[27540 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russia_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename some countries and regions or remove them to join two shape and data dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "<ipython-input-6-300d2728652f>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  russia_shape_df.dropna(subset = ['name_ru'], inplace = True)\n",
      "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/usr/local/lib/python3.8/dist-packages/geopandas/geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "for data, shape in [\n",
    "    ('North Macedonia', 'Macedonia'),\n",
    "    ('Holy See', 'Vatican'),\n",
    "    ('Cote d\\'Ivoire', 'Ivory Coast'),\n",
    "    ('Congo (Kinshasa)', 'Democratic Republic of the Congo'),\n",
    "    ('Congo (Brazzaville)', 'Republic of the Congo'),\n",
    "    ('Bahamas', 'The Bahamas'),\n",
    "    ('Serbia', 'Republic of Serbia'),\n",
    "    ('Sao Tome and Principe', 'São Tomé and Principe'),\n",
    "    ('Tanzania', 'United Republic of Tanzania'),\n",
    "    ('UK', 'United Kingdom'),\n",
    "    ('US', 'United States of America')\n",
    "]:\n",
    "    world_report_df.loc[world_report_df.Name == data, 'Name'] = shape\n",
    "    \n",
    "for to_remove in ['West Bank and Gaza', 'Timor-Leste']:\n",
    "    world_report_df = world_report_df[world_report_df.Name != to_remove]\n",
    "    \n",
    "world_shape_df.loc[world_shape_df['ADMIN'] == 'Baykonur Cosmodrome', 'ADMIN'] = 'Kazakhstan'\n",
    "\n",
    "\n",
    "if not args[0].minimal:\n",
    "    russia_shape_df.loc[1442, 'name_ru'] = \"Алтайский край\"\n",
    "    russia_shape_df.dropna(subset = ['name_ru'], inplace = True)\n",
    "    \n",
    "    for data, shape in [\n",
    "        ('Крым', 'Автономная Республика Крым'),\n",
    "        ('Алтай', 'Республика Алтай'),\n",
    "        ('Еврейская АО', 'Еврейская автономная область'),\n",
    "        ('Карачаево-Черкессия', 'Карачаево-Черкесия'),\n",
    "        ('Карелия', 'Республика Карелия'),\n",
    "        ('Коми', 'Республика Коми'),\n",
    "        ('Ненецкий АО', 'Ненецкий автономный округ'),\n",
    "        ('Северная Осетия', 'Республика Северная Осетия-Алания'),\n",
    "        ('Саха (Якутия)', 'Якутия'),\n",
    "        ('ХМАО – Югра', 'Ханты-Мансийский автономный округ — Югра'),\n",
    "        ('Чукотский АО', 'Чукотский автономный округ'),\n",
    "        ('Ямало-Ненецкий АО', 'Ямало-Ненецкий автономный округ'),\n",
    "    ]:\n",
    "        russia_shape_df.loc[russia_shape_df.name_ru == shape, 'name_ru'] = data\n",
    "        \n",
    "    russia_shape_df['name_ru'] = russia_shape_df['name_ru'].apply(lambda x: x[:-4] +'.' if x.endswith('область') else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare shapes dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_shape_df = world_shape_df.to_crs('epsg:4326')\n",
    "europe_shape_df = world_shape_df.loc[world_shape_df.ADMIN.isin(set(world_report_df.loc[world_report_df.Continent=='Europe','Name']))]\n",
    "\n",
    "if not args[0].minimal:\n",
    "    russia_shape_df = russia_shape_df.to_crs('epsg:5940')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparations for images rendering:\n",
    "- Set fin, step variables\n",
    "- Set pool_size. CAUTION: Big values could lead to out of memory exceptions and to kernel crash\n",
    "- Set cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = utils.one_day\n",
    "fin =  utils.last_day\n",
    "pool_size = max(1, int(cpu_count()*.75))\n",
    "sea_color = '#CBE8FE'\n",
    "\n",
    "cmap_general = colors.LinearSegmentedColormap.from_list('test',\n",
    " [\n",
    "     (0,'#00cc00'),\n",
    "     (0.2,'#28a428'),\n",
    "     (0.4,'#7ba428'), \n",
    "     (0.5,'#ccad00'),\n",
    "     (0.7,'#e69500'),\n",
    "     (0.9,'#cc3600'), \n",
    "     (1,'#ba1234')\n",
    " ])\n",
    "\n",
    "cmap_deaths = colors.LinearSegmentedColormap.from_list('test',\n",
    " [\n",
    "     (0,'#e9edee'),\n",
    "     (0.1,'#ffff91'),\n",
    "     (0.2,'#ff713f'), \n",
    "     (0.5,'#a42c2b'),\n",
    "     (0.7,'#595959'),\n",
    "     (1,'#000000')\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = None, None\n",
    "\n",
    "def get_fig_axes(cmap, norm):\n",
    "    fig = pyplot.figure(figsize=(24,14))\n",
    "    fig.set_tight_layout({\"pad\":0.1})\n",
    "        \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"1%\", pad=0.05)\n",
    "    fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax,cax=cax,orientation='horizontal')\n",
    "   \n",
    "    return fig, ax\n",
    "\n",
    "def draw_top_10(df, name_column, data_column, ax, \n",
    "                name_name='Country', data_name = 'Cases',\n",
    "                as_int = True, x0 = 0.01, y0 = 0.01):\n",
    "    formatter = (lambda x: '{:d}'.format(int(x))) if as_int else (lambda x: '{:.2f}'.format(float(x)))\n",
    "    table_data =list(\n",
    "        df.dropna(subset=[data_column]).sort_values(\n",
    "            by = data_column,\n",
    "            ascending = False).head(10)[[name_column, data_column]].apply(\n",
    "            lambda x: [x[name_column], formatter(x[data_column])], axis=1).values)\n",
    "    \n",
    "    count = len(table_data)\n",
    "    \n",
    "    if count > 0:\n",
    "        table = ax.table(table_data,\n",
    "                         colLabels=[name_name, data_name],\n",
    "                         rowLabels=list(range(1, count+1)),\n",
    "                         colWidths=[2, 1],\n",
    "                         cellColours=np.reshape(np.repeat(sea_color, 2*count), (count, 2)),\n",
    "                         rowColours = np.repeat(sea_color, count),\n",
    "                         colColours = np.repeat(sea_color, 2),\n",
    "                         bbox=[x0, y0, .2, .027*(count+1)])\n",
    "        \n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)    \n",
    "\n",
    "def process_day (day,\n",
    "                 shape_df,\n",
    "                 report_df,\n",
    "                 column_name,\n",
    "                 vmin,\n",
    "                 vmax,\n",
    "                 cmap,\n",
    "                 norm,\n",
    "                 annotation_text,\n",
    "                 folder_name,\n",
    "                 frame_title = None,\n",
    "                 ax_xlim = (-180, 180),\n",
    "                 ax_ylim = (-90,90),\n",
    "                 annotation_table_column_name = 'Country',\n",
    "                 annotation_table_column_data = 'Cases',\n",
    "                 annotation_table_data_as_int = True,\n",
    "                 annotation_table_x0 = 0.01,\n",
    "                 annotation_table_y0 = 0.01,\n",
    "                 shape_df_index = 'ADMIN', \n",
    "                 report_df_index = 'Name'):\n",
    "    global fig, ax\n",
    "    if not fig:\n",
    "        fig,ax = get_fig_axes(cmap, norm)\n",
    "        \n",
    "    if ax_xlim:\n",
    "        ax.set_xlim(ax_xlim[0],ax_xlim[1])\n",
    "        \n",
    "    if ax_ylim:\n",
    "        ax.set_ylim(ax_ylim[0],ax_ylim[1])\n",
    "        \n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    if frame_title:\n",
    "        fig.suptitle(frame_title, fontsize = 36)\n",
    "        \n",
    "    temp_df = shape_df.set_index(shape_df_index).join(report_df[report_df.Date == day].set_index(report_df_index)[column_name]).reset_index()\n",
    "        \n",
    "    temp_df.plot(ax=ax, color='white', edgecolor='black', linewidth=1)\n",
    "    temp_df.plot(ax=ax, column=column_name, linewidth=0, vmin=vmin, vmax=vmax, cmap=cmap, norm=norm, alpha=0.9)\n",
    "    \n",
    "    ax.annotate(annotation_text, xy=(20,950), xycoords='figure pixels', fontsize=24)\n",
    "    draw_top_10(temp_df, \n",
    "                shape_df_index,\n",
    "                column_name, \n",
    "                ax, \n",
    "                name_name = annotation_table_column_name,\n",
    "                data_name = annotation_table_column_data,\n",
    "                as_int = annotation_table_data_as_int,\n",
    "                x0 = annotation_table_x0,\n",
    "                y0 = annotation_table_y0)\n",
    "    \n",
    "    fig.savefig(f'./temp/{folder_name}/{day.date().strftime(\"%Y-%m-%d\")}.jpg', dpi=72, facecolor=sea_color)    \n",
    "    ax.clear()\n",
    "\n",
    "\n",
    "def make_video(name, clean_data = True):\n",
    "    images = list(os.listdir(f'./temp/{name}'))\n",
    "\n",
    "    with imageio.get_writer(f'./assets/video/{name}.mp4', mode='I', fps=6) as writer:\n",
    "        for i in range(len(images)):\n",
    "            image = imageio.imread(os.path.join(os.path.abspath(f'./temp/{name}'),images[i]))\n",
    "            writer.append_data(image)\n",
    "            \n",
    "    if clean_data:\n",
    "        shutil.rmtree(f'./temp/{name}')\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "data_selector = {\n",
    "    'world' : (\n",
    "        world_shape_df,\n",
    "        world_report_df,\n",
    "        utils.first_day,\n",
    "        (-180, 180),\n",
    "        (-90, 90),\n",
    "        (0.01, 0.1)\n",
    "    ),\n",
    "        \n",
    "    'europe' : (\n",
    "        europe_shape_df,\n",
    "        world_report_df,\n",
    "        utils.str_to_datetime('01-02-2020'),\n",
    "        (-20, 50),\n",
    "        (30, 73),\n",
    "        (-0.05, 0.01)\n",
    "    ),\n",
    "        \n",
    "    'russia' : (\n",
    "        russia_shape_df, \n",
    "        russia_report_df,\n",
    "        utils.str_to_datetime('15-03-2020'),\n",
    "        None,\n",
    "        None,\n",
    "        (0.01, 0.01)\n",
    "    )\n",
    "}\n",
    "        \n",
    "get_shape_index = lambda shape: \"name_ru\" if shape == 'russia' else 'ADMIN'\n",
    "get_as_int = lambda column, suffix: column != 'Rt' and suffix == ''\n",
    "get_table_column_name = lambda shape: \"Region\" if shape == 'russia' else \"Country\"\n",
    "get_folder_name = lambda shape, column, suffix: (f'{shape}_{column}_{suffix}' if suffix else f'{shape}_{column}').lower()\n",
    "get_cmap = lambda column: cmap_deaths if (column == 'Deaths') or (column == 'Deaths_Change') else cmap_general\n",
    "\n",
    "def get_table_column_data (column, suffix):\n",
    "    if suffix == '100k':\n",
    "        return 'Cases per 100k'\n",
    "    elif suffix == 'Norm':\n",
    "        return 'Fraction from max'\n",
    "    elif suffix.startswith(\"SMA\"):\n",
    "        return 'Sliding mean avg'\n",
    "    elif column == 'Rt':\n",
    "        return r'$R_t$'\n",
    "    \n",
    "    return 'Cases'\n",
    "\n",
    "def get_column_name (column, suffix):\n",
    "    if suffix == '100k':\n",
    "        return column + '_per_100k'\n",
    "    elif suffix == 'Norm' or suffix.startswith(\"SMA\"):\n",
    "        return f'{column}_{suffix}'\n",
    "    \n",
    "    return column\n",
    "\n",
    "def get_frame_title(shape, column, suffix):\n",
    "    if shape == 'russia':\n",
    "        shape_part = 'Regions'\n",
    "    else:\n",
    "        shape_part = 'Countries'\n",
    "    \n",
    "    if column == 'Rt':\n",
    "        column_part = r'$R_t$' \n",
    "    elif column == 'Confirmed_Change':\n",
    "        column_part = 'new cases per day'\n",
    "    elif column == 'Deaths_Change':\n",
    "        column_part = 'deaths per day'\n",
    "    else:\n",
    "        column_part = column.lower()\n",
    "        \n",
    "    if suffix == '100k':\n",
    "        suffix_part = 'per 100k people'\n",
    "    elif suffix == 'Norm':\n",
    "        suffix_part = 'normalized by min-max'\n",
    "    elif suffix.startswith('SMA'):\n",
    "        suffix_part = f'sliding mean average for {suffix[4:]} days'\n",
    "        \n",
    "    return f'{shape_part} {column_part} {suffix_part}' if suffix != '' else f'{shape_part} {column_part}'\n",
    "\n",
    "def get_vmin_vmax(report_df, column, suffix):\n",
    "    column_name = get_column_name(column, suffix)\n",
    "    if (suffix == 'Norm'):\n",
    "        return 0, 1\n",
    "    \n",
    "    elif (column == 'Rt'):\n",
    "        return 0, 2\n",
    "    \n",
    "    elif (column == 'Confirmed_Change' or column == 'Deaths_Change'):\n",
    "        max_values = list()\n",
    "        \n",
    "        for name in set(report_df.Name):\n",
    "            name_values = report_df.loc[report_df.Name == name, column_name]\n",
    "            max_value = name_values.dropna().max()\n",
    "            if not np.isnan(max_value):\n",
    "                max_values.append(max_value)\n",
    "            \n",
    "        return max(1, np.quantile(max_values, .05)), np.quantile(max_values, .95)\n",
    "\n",
    "    return max(1, report_df.loc[report_df.Date == fin, column_name].quantile(.05)), report_df.loc[report_df.Date == fin, column_name].quantile(.95)\n",
    "\n",
    "def get_norm(column, suffix, vmin, vmax):\n",
    "    if (suffix == 'Norm'):\n",
    "        return colors.Normalize(vmin, vmax)\n",
    "    elif (column == 'Rt'):\n",
    "        return colors.Normalize(.9, 1.1)\n",
    "    \n",
    "    return colors.LogNorm(vmin, vmax)\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def generate_frames(shape, column, suffix, idx, total):    \n",
    "    shape_df, report_df, start, ax_xlim, ax_ylim, table_offset = data_selector[shape]\n",
    "    column_name = get_column_name (column, suffix)\n",
    "    vmin, vmax = get_vmin_vmax (report_df, column, suffix)\n",
    "    cmap = get_cmap (column)\n",
    "    norm = get_norm (column, suffix, vmin, vmax)\n",
    "    folder_name = get_folder_name (shape, column, suffix)\n",
    "    frame_title = get_frame_title (shape, column, suffix)\n",
    "    table_column_name = get_table_column_name (shape)\n",
    "    table_column_data = get_table_column_data (column, suffix)\n",
    "    as_int = get_as_int (column, suffix)\n",
    "    shape_index = get_shape_index (shape)\n",
    "    \n",
    "    if not os.path.exists(f'./temp/{folder_name}'):\n",
    "        os.mkdir(f'./temp/{folder_name}')\n",
    "\n",
    "##    if True:\n",
    "    with Pool(pool_size) as frames_pool:\n",
    "        frames = list()\n",
    "\n",
    "        for i in range ((fin - start).days + 1):\n",
    "            day = start + step*i\n",
    "            annotation_text = day.date().strftime('%Y-%m-%d')\n",
    "\n",
    "            frames.append(frames_pool.apply_async(\n",
    "                process_day,\n",
    "                [\n",
    "##            process_day(\n",
    "                    day,\n",
    "                    shape_df,\n",
    "                    report_df,\n",
    "                    column_name,\n",
    "                    vmin,\n",
    "                    vmax,\n",
    "                    cmap,\n",
    "                    norm,\n",
    "                    annotation_text,\n",
    "                    folder_name,\n",
    "                    frame_title,\n",
    "                    ax_xlim,\n",
    "                    ax_ylim,\n",
    "                    table_column_name,\n",
    "                    table_column_data,\n",
    "                    as_int,\n",
    "                    table_offset[0],\n",
    "                    table_offset[1],\n",
    "                    shape_index\n",
    "                ]))\n",
    "##)\n",
    "\n",
    "        for frame in tqdm(frames, desc=f'({idx}/{total}) Frames for {shape} - {column_name}'): \n",
    "            frame.wait()\n",
    "        \n",
    "    return folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR DEBUG ONLY\n",
    "#generate_frames('europe','Deaths_Change','SMA_7',1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/36) Frames for world - Confirmed: 100%|██████████| 333/333 [01:34<00:00,  3.51it/s]\n",
      "(2/36) Frames for world - Confirmed_per_100k: 100%|██████████| 333/333 [01:42<00:00,  3.23it/s]\n",
      "(3/36) Frames for world - Confirmed_Norm: 100%|██████████| 333/333 [01:37<00:00,  3.41it/s]\n",
      "(4/36) Frames for world - Deaths: 100%|██████████| 333/333 [01:40<00:00,  3.32it/s]\n",
      "(5/36) Frames for world - Deaths_per_100k: 100%|██████████| 333/333 [01:39<00:00,  3.34it/s]\n",
      "(6/36) Frames for world - Deaths_Norm: 100%|██████████| 333/333 [01:46<00:00,  3.11it/s]\n",
      "(7/36) Frames for world - Confirmed_Change: 100%|██████████| 333/333 [01:38<00:00,  3.38it/s]\n",
      "(8/36) Frames for world - Confirmed_Change_per_100k: 100%|██████████| 333/333 [01:41<00:00,  3.28it/s]\n",
      "(9/36) Frames for world - Confirmed_Change_Norm: 100%|██████████| 333/333 [01:39<00:00,  3.36it/s]\n",
      "(10/36) Frames for world - Deaths_Change: 100%|██████████| 333/333 [01:43<00:00,  3.21it/s]\n",
      "(11/36) Frames for world - Deaths_Change_per_100k: 100%|██████████| 333/333 [01:39<00:00,  3.35it/s]\n",
      "(12/36) Frames for world - Deaths_Change_Norm: 100%|██████████| 333/333 [01:37<00:00,  3.42it/s]\n",
      "(13/36) Frames for europe - Confirmed: 100%|██████████| 323/323 [01:05<00:00,  4.92it/s]\n",
      "(14/36) Frames for europe - Confirmed_per_100k: 100%|██████████| 323/323 [01:06<00:00,  4.89it/s]\n",
      "(15/36) Frames for europe - Confirmed_Norm: 100%|██████████| 323/323 [01:01<00:00,  5.28it/s]\n",
      "(16/36) Frames for europe - Deaths: 100%|██████████| 323/323 [01:02<00:00,  5.20it/s]\n",
      "(17/36) Frames for europe - Deaths_per_100k: 100%|██████████| 323/323 [01:01<00:00,  5.26it/s]\n",
      "(18/36) Frames for europe - Deaths_Norm: 100%|██████████| 323/323 [01:00<00:00,  5.36it/s]\n",
      "(19/36) Frames for europe - Confirmed_Change: 100%|██████████| 323/323 [01:03<00:00,  5.08it/s]\n",
      "(20/36) Frames for europe - Confirmed_Change_per_100k: 100%|██████████| 323/323 [01:05<00:00,  4.91it/s]\n",
      "(21/36) Frames for europe - Confirmed_Change_Norm: 100%|██████████| 323/323 [01:00<00:00,  5.37it/s]\n",
      "(22/36) Frames for europe - Deaths_Change: 100%|██████████| 323/323 [01:01<00:00,  5.27it/s]\n",
      "(23/36) Frames for europe - Deaths_Change_per_100k: 100%|██████████| 323/323 [01:00<00:00,  5.31it/s]\n",
      "(24/36) Frames for europe - Deaths_Change_Norm: 100%|██████████| 323/323 [01:00<00:00,  5.32it/s]\n",
      "(25/36) Frames for russia - Confirmed: 100%|██████████| 280/280 [00:27<00:00, 10.32it/s]\n",
      "(26/36) Frames for russia - Confirmed_per_100k: 100%|██████████| 280/280 [00:28<00:00,  9.99it/s]\n",
      "(27/36) Frames for russia - Confirmed_Norm: 100%|██████████| 280/280 [00:27<00:00, 10.02it/s]\n",
      "(28/36) Frames for russia - Deaths: 100%|██████████| 280/280 [00:30<00:00,  9.28it/s]\n",
      "(29/36) Frames for russia - Deaths_per_100k: 100%|██████████| 280/280 [00:26<00:00, 10.44it/s]\n",
      "(30/36) Frames for russia - Deaths_Norm: 100%|██████████| 280/280 [00:26<00:00, 10.62it/s]\n",
      "(31/36) Frames for russia - Confirmed_Change: 100%|██████████| 280/280 [00:26<00:00, 10.55it/s]\n",
      "(32/36) Frames for russia - Confirmed_Change_per_100k: 100%|██████████| 280/280 [00:26<00:00, 10.51it/s]\n",
      "(33/36) Frames for russia - Confirmed_Change_Norm: 100%|██████████| 280/280 [00:26<00:00, 10.57it/s]\n",
      "(34/36) Frames for russia - Deaths_Change: 100%|██████████| 280/280 [00:26<00:00, 10.51it/s]\n",
      "(35/36) Frames for russia - Deaths_Change_per_100k: 100%|██████████| 280/280 [00:27<00:00, 10.36it/s]\n",
      "(36/36) Frames for russia - Deaths_Change_Norm: 100%|██████████| 280/280 [00:26<00:00, 10.51it/s]\n",
      "Videos rendered: 100%|██████████| 36/36 [00:08<00:00,  4.24it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    shapes = ['world', 'europe'] if args[0].minimal else ['world', 'europe', 'russia']\n",
    "    columns = ['Confirmed', 'Deaths'] if args[0].minimal else ['Confirmed', 'Deaths', 'Confirmed_Change', 'Deaths_Change']\n",
    "    suffixes = ['', '100k'] if args[0].minimal else ['', '100k', 'Norm']\n",
    "    \n",
    "    all_variants = list(itertools.product(shapes, columns, suffixes))\n",
    "\n",
    "    with Pool(1) as videos_pool:\n",
    "        videos = list()\n",
    "        idx = 1\n",
    "    \n",
    "        for shape, column, suffix in all_variants:\n",
    "            folder = generate_frames(shape, column, suffix, idx, len(all_variants))\n",
    "            videos.append(videos_pool.apply_async(make_video, [folder]))\n",
    "            idx = idx + 1\n",
    "        \n",
    "        for video in tqdm(videos, desc=\"Videos rendered\"): \n",
    "            video.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
